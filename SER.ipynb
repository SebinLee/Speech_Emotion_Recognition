{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speech Emotion Recognition\n",
    "이 jupyter notebook에서는 사용자의 음성을 통한(특히 콘서트 상황에서의) 감정 인식을 진행합니다.  \n",
    "참고한 논문은 다음과 같습니다.\n",
    "\n",
    "- CHATTERJEE, Rajdeep, et al. Real-time speech emotion analysis for smart home assistants. IEEE Transactions on Consumer Electronics, 2021, 67.1: 68-76."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np     \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "# Live Audio\n",
    "import librosa                                      \n",
    "import librosa.display                         \n",
    "from scipy.fftpack import fft                  \n",
    "from scipy.io.wavfile import write\n",
    "from sklearn.decomposition import FastICA\n",
    "from sklearn.preprocessing import normalize, scale, LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you use local machine, run this cell\n",
    "file_root = \"/Users/sebinlee/Desktop/Github/SERPractice\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA = os.path.join(file_root, \"audio-dataset\")\n",
    "TRAIN_DATA_OUTPUT = os.path.join(file_root,\"audio-dataset/output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_pad_len = 174\n",
    "\n",
    "def pre_processing(audio_file_path) :\n",
    "    # Load Audio File\n",
    "    audio_timeseries, sampling_rate = librosa.load(audio_file_path)\n",
    "\n",
    "    # Silence Removal\n",
    "    audio_timeseries, _ = librosa.effects.trim(audio_timeseries)\n",
    "\n",
    "    # Declare variable  \n",
    "    n_fft = 2048\n",
    "    hop_length = 512\n",
    "\n",
    "    # Get mfcc\n",
    "    mfcc = librosa.feature.mfcc(audio_timeseries, sr=sampling_rate, hop_length=hop_length, n_fft=n_fft, dct_type=3, n_mfcc=13)\n",
    "    # librosa.display.specshow(mfcc, sr=sampling_rate, x_axis='time')\n",
    "\n",
    "    # Make Padding to match length\n",
    "    pad_width = max_pad_len - mfcc.shape[1]\n",
    "    mfcc = np.pad(mfcc, pad_width = ((0,0),(0,pad_width)), mode=\"constant\")\n",
    "\n",
    "    return mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "valence_dict = {\n",
    "    \"achievement\" : 1,\n",
    "    \"pleasure\" : 2,\n",
    "    \"surprise\" : 3,\n",
    "    \"anger\" : -1,\n",
    "    \"fear\" : -2,\n",
    "    \"pain\" : -3,\n",
    "}\n",
    "\n",
    "arousal_dict = {\n",
    "    \"low\" : 1,\n",
    "    \"moderate\" : 2,\n",
    "    \"strong\" : 3,\n",
    "    \"peak\" : 4\n",
    "}\n",
    "\n",
    "def vivae_fetch_label(file_path) :\n",
    "    file_name = file_path[len(TRAIN_DATA) + 1 :]\n",
    "    splited = file_name.split(\"_\")\n",
    "    return [valence_dict[splited[1]], arousal_dict[splited[2]]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file_list = glob.glob(os.path.join(TRAIN_DATA, \"*\"))\n",
    "features = []\n",
    "\n",
    "# Append [mfcc, valence, arousal]\n",
    "for file_path in train_file_list :\n",
    "    valence_arousal = vivae_fetch_label(file_path)\n",
    "    features.append([pre_processing(file_path), valence_arousal[0], valence_arousal[1]])\n",
    "\n",
    "# Convert features variable to Pandas DataFrame\n",
    "featuresDF = pd.DataFrame(features, columns=['features', 'valence', 'arousal'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Conv1D(128,5,padding='causal',activation='relu', input_shape=(13,max_pad_len)))\n",
    "model.add(tf.keras.layers.Conv1D(128,5,padding='causal',activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling1D(pool_size=8))\n",
    "model.add(tf.keras.layers.Conv1D(128,5,padding='causal',activation='relu'))\n",
    "model.add(tf.keras.layers.Conv1D(128,5,padding='causal',activation='relu'))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(10, activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "model.compile(loss=tf.losses.MeanAbsoluteError(), optimizer='adam', metrics=['accuracy'])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1085, 13, 174)\n",
      "(1085, 6)\n"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "features_list = np.array(featuresDF.features.tolist())\n",
    "valence_list = np.array(featuresDF.valence.tolist())\n",
    "\n",
    "train_data = features_list\n",
    "train_result = tf.keras.utils.to_categorical(le.fit_transform(valence_list))\n",
    "\n",
    "print(train_data.shape)\n",
    "print(train_result.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/Users/sebinlee/miniforge3/envs/tf38/lib/python3.8/site-packages/keras/engine/training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/sebinlee/miniforge3/envs/tf38/lib/python3.8/site-packages/keras/engine/training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/sebinlee/miniforge3/envs/tf38/lib/python3.8/site-packages/keras/engine/training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/sebinlee/miniforge3/envs/tf38/lib/python3.8/site-packages/keras/engine/training.py\", line 860, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/Users/sebinlee/miniforge3/envs/tf38/lib/python3.8/site-packages/keras/engine/training.py\", line 918, in compute_loss\n        return self.compiled_loss(\n    File \"/Users/sebinlee/miniforge3/envs/tf38/lib/python3.8/site-packages/keras/engine/compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/Users/sebinlee/miniforge3/envs/tf38/lib/python3.8/site-packages/keras/losses.py\", line 141, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/Users/sebinlee/miniforge3/envs/tf38/lib/python3.8/site-packages/keras/losses.py\", line 245, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/Users/sebinlee/miniforge3/envs/tf38/lib/python3.8/site-packages/keras/losses.py\", line 1457, in mean_absolute_error\n        return backend.mean(tf.abs(y_pred - y_true), axis=-1)\n\n    ValueError: Dimensions must be equal, but are 10 and 6 for '{{node mean_absolute_error/sub}} = Sub[T=DT_FLOAT](sequential_32/dense_41/Softmax, IteratorGetNext:1)' with input shapes: [?,10], [?,6].\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/sebinlee/Desktop/Github/SERPractice/SER.ipynb Cell 12'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/sebinlee/Desktop/Github/SERPractice/SER.ipynb#ch0000020?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(train_data, train_result, epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m)\n",
      "File \u001b[0;32m~/miniforge3/envs/tf38/lib/python3.8/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     <a href='file:///~/miniforge3/envs/tf38/lib/python3.8/site-packages/keras/utils/traceback_utils.py?line=64'>65</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     <a href='file:///~/miniforge3/envs/tf38/lib/python3.8/site-packages/keras/utils/traceback_utils.py?line=65'>66</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m---> <a href='file:///~/miniforge3/envs/tf38/lib/python3.8/site-packages/keras/utils/traceback_utils.py?line=66'>67</a>\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     <a href='file:///~/miniforge3/envs/tf38/lib/python3.8/site-packages/keras/utils/traceback_utils.py?line=67'>68</a>\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     <a href='file:///~/miniforge3/envs/tf38/lib/python3.8/site-packages/keras/utils/traceback_utils.py?line=68'>69</a>\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniforge3/envs/tf38/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py:1147\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///~/miniforge3/envs/tf38/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py?line=1144'>1145</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/miniforge3/envs/tf38/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py?line=1145'>1146</a>\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m-> <a href='file:///~/miniforge3/envs/tf38/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py?line=1146'>1147</a>\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mag_error_metadata\u001b[39m.\u001b[39mto_exception(e)\n\u001b[1;32m   <a href='file:///~/miniforge3/envs/tf38/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py?line=1147'>1148</a>\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   <a href='file:///~/miniforge3/envs/tf38/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py?line=1148'>1149</a>\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/Users/sebinlee/miniforge3/envs/tf38/lib/python3.8/site-packages/keras/engine/training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/sebinlee/miniforge3/envs/tf38/lib/python3.8/site-packages/keras/engine/training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/sebinlee/miniforge3/envs/tf38/lib/python3.8/site-packages/keras/engine/training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/sebinlee/miniforge3/envs/tf38/lib/python3.8/site-packages/keras/engine/training.py\", line 860, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/Users/sebinlee/miniforge3/envs/tf38/lib/python3.8/site-packages/keras/engine/training.py\", line 918, in compute_loss\n        return self.compiled_loss(\n    File \"/Users/sebinlee/miniforge3/envs/tf38/lib/python3.8/site-packages/keras/engine/compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/Users/sebinlee/miniforge3/envs/tf38/lib/python3.8/site-packages/keras/losses.py\", line 141, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/Users/sebinlee/miniforge3/envs/tf38/lib/python3.8/site-packages/keras/losses.py\", line 245, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/Users/sebinlee/miniforge3/envs/tf38/lib/python3.8/site-packages/keras/losses.py\", line 1457, in mean_absolute_error\n        return backend.mean(tf.abs(y_pred - y_true), axis=-1)\n\n    ValueError: Dimensions must be equal, but are 10 and 6 for '{{node mean_absolute_error/sub}} = Sub[T=DT_FLOAT](sequential_32/dense_41/Softmax, IteratorGetNext:1)' with input shapes: [?,10], [?,6].\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_data, train_result, epochs=10)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ce9d5f3b762a4b809da740276dc6ee13f977563119004a7897d396360c07ebaf"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('tf38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
